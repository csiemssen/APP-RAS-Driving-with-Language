### Papers
- LingoQA: Visual Question Answering for Autonomous Driving
  - https://github.com/wayveai/LingoQA
- DriveLM: Driving with Graph Visual Question Answering
  - https://github.com/OpenDriveLab/DriveLM
  - Precise Drive with VLM: First Prize Solution for PRCV 2024 Drive LM challenge
- CVPR 2024 - Autonomous Grand Challenge, Drive with language
  - https://huggingface.co/spaces/AGC2024/driving-with-language-official
- Gemini Robotics: Bringing AI into the Physical World
- Talk2BEV: Language-enhanced Birdâ€™s-eye View Maps for Autonomous Driving
  - https://llmbev.github.io/talk2bev/
- NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for Autonomous Driving Scenario
  - https://github.com/qiantianwen/NuScenes-QA
- RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model

### Frameworks (Fine-tuning)
- All expect DS to be in specific formats (e.g., ShareGPT)
- Unsloth (supposedly fast)
- LLaMA-Factory (used by previous group)
- TRL (integrated in HF)
- axolotl (YAML config)

### LLMs/VLMs
- Qwen (previous group - Qwen2-VL-7B-Instruct)
- Lmsys (LingoQA Baseline - Vicuna-7B)
- BLIP-2 (DriveLM Baseline)
- Meta-llama
- Google-Gemma
- Molmo
- Mistral
- DeepSeek
- ...

### Datasets
- BDD-X-dataset
- Waymo Open Dataset
- NuScences
- LingoQA Datasets
